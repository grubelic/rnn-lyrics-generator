\documentclass[conference]{IEEEtran}
% \IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} % hrvatski
\usepackage{currvita} % hrvatski
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[super]{nth}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Generating song lyrics using recurrent neural networks\\
{\footnotesize Project for the course \textit{Neural Networks} at Faculty of
Electrical Engineering and Computing, University of Zagreb}
}

\author{
\IEEEauthorblockN{Ena Car}
\IEEEauthorblockA{Ena.Car@fer.hr}
\and
\IEEEauthorblockN{Pavao Dužević}
\IEEEauthorblockA{Pavao.Duzevic@fer.hr}
\and
\IEEEauthorblockN{Damjan Grubelić}
\IEEEauthorblockA{Damjan.Grubelic@fer.hr}
\and
\IEEEauthorblockN{Josipa Kaselj}
\IEEEauthorblockA{Josipa.Kaselj@fer.hr}
\and
\IEEEauthorblockN{Magdalena Šimunec}
\IEEEauthorblockA{Magdalena.Simunec@fer.hr}
\and
\IEEEauthorblockN{Eva Šmuc}
\IEEEauthorblockA{Eva.Smuc@fer.hr}
}

\maketitle

\begin{abstract}
This document is a project report for the Neural Networks course at Faculty of
Electrical Engineering and Computing in Zagreb. It describes an implementation
of a recursive neural network which is used for generating song lyrics based
on given set of song lyrics.
\end{abstract}

\begin{IEEEkeywords}
RNN, neural networks, generating song lyrics
\end{IEEEkeywords}

\section{Introduction}
Writing meaningful lyrics has always been a challenge even to the best of
songwriters. Since more and more jobs are being automated, especially now with
the rise of popularity of various machine learning methods, there is also an
initiative aimed at computers writing songs.
The goal is to feed a model with lyrics of existing songs and then to use it for
generating new lyrics. Those generated song lyrics aren't supposed to be
word-for-word equal to those used for training the model. Still, it wouldn't be
sensible having it generate random words, either. The goal is having the model 
memorize the lyrics of the songs it is trained on (motifs) and then combine them
\textit{sensibly}, i.e. having the model memorize "relationships" between the
words through their relative order.
In this project, it is being done using recursive neural networks (RNN), which
are able to take in account previous outputs when generating new one, thus
adding temporality. 
The models have been trained on several subsets of the "150K Lyrics Labeled with 
Spotify Valence" dataset from \textit{kaggle.com}.

\section{Existing solutions and brief literature overview}

\subsection{Automatic Rap Lyrics Generation}
Variation of RNN called LSTM architecture creates a better language model than a regular RNN. \cite{b1}
According to Potash, Romanov and Rumshisky, Long Short-Term Memory (LSTM) language model
produces better lyrics than a baseline model. They attempted to piece together lyrics for a specific artist, but
their model was limited in generating lyrics for a genre. As a result of training their model with sets of lyrics, they
noticed corresponding rhyming words. \vspace{2.5mm}

Another example of A Rap Lyrics Generator was developed by Nguyen and Sa \cite{b2}.
They used database of approximately 40000 existing rap lyrics. After failure to get profound results when using 
linear-interpolated trigram model approach, they shifted to a quadgram model. Also, they succeeded to generate sentences 
that rhyme with each other. At the end, generator worked decently, but the content of the lyrics did not relate to a specific theme.

\subsection{Automatic Generation of Poems}
Wishful Automatic Spanish Poet was the first generating program for poems which used artificial intelligence and natural language
generation techniques together. The whole system of WASP is based on a forward reasoning ruled-based system.
Users were asked for inputs which were then used as seeds and results recieved were not very efficient in generating lyrics \cite{b3}.

\subsection{Rhyme Detection}
Hirjee and Brown have developed a probabilistic model and in addition to it they have built up a rhyme detection tool based on that model \cite{b4} \cite{b5}.
Tool analyzes phoneme patterns in words and model is trained on a set of lyrics that were manually annotated for rhyming words.

\subsection{Classification of Lyrics}
Mayer, Neumayer and Rauber used rhyme and style features to classify and process lyrics \cite{b6}. 
They followed the fact that a rhyme is two words that when spelt sound similar and generally used it for words at the end of verses.

\subsection{Natural Language Processing and Lyrics Generation}
With basic natural language processing tools, song lyrics can be analysed by using a Naive Bayes classifier. Mahedero, Cano and Martinez used that to 
identify languages. Also, they used it for classification based on themes and to search for similarities between them. 
The languages which were used for the experiment: English, Spanish, German, French and Italian. Given results were approximately 94\% accurate.
The conclusion they came to is that the identification of languages was easier task compared to the others.

\section{Solution implemented by the project team} % mozda bolji naslov?
Since generating the lyrics requires memorizing word ordering so that lyrics
make sense, RNNs have been used, as that class of neural networks is better for
memorizing sequences. Sequences used as RNN inputs can be words as well as
characters. In this project, the word-based model has been used, so that
all generated lyrics use existing words and the RNN doesn't have to memorize
character ordering inside the words on top of word order.

\subsection{Choosing the right dataset}
The lyrics needed for training such model can be scraped using the webscrapers on
lyrics websites, downloaded using a Python API like \textit{lyricsgenius} or
downloaded as a readily available dataset. With the latter being the simplest
method of the three, yet equally suitable, the project team opted for the
"150K Lyrics Labeled with Spotify Valence" dataset because of its exhaustiveness
which provides a simple way to extract almost any arists' lyrics and  offers
diversity of songs and genres. Since it is too big to be processed on the
project team's machines, only the first 200 lyrics with more than 60\% English
words in them have been used for training the most of the models.

\subsection{Preprocessing the dataset}
Since the lyrics texts often contain additional info that is not part of actual
song lyrics (like the chorus tag or the name of the artist performing the
next verses) and since such tags are most commonly enclosed in square brackets,
everything inside square brackets has been removed from the lyrics to
reduce cluttering with info that may not be correct in generated lyrics and
would interfere with memorizing relationships of words and motiffs.

However, another kind of interference was made in
order to memorize line endings. The "word" \textit{endl} has been added to the
end of each line in order to help with rhyming and breaking lines of
generated songs in meaningful places.

After adding the \textit{endl}, each word from the dataset has been stripped of
punctuation and converted to lowercase. Each word has been mapped to a unique
number that would be used as network input.

Those numbers (tokenized words) have been grouped into sequences of 
\textbf{up to} $n$ lines, i.e. verses. The sequences have been padded to the
length of the longest sequence with zeros. The last number in each sequence
would later be expected output for the input which is the rest of the sequence.

\subsection{Building the models}
Three different architectures of neural network have been used in order to determine which one would provide the best results.
Basic network architecture consists of an input layer, one or multiple hidden layers and an output layer.

First architecture consists of one hidden SimpleRNN layer, which is a fully-connected RNN where the output is to be fed back to input.

Second architecture has an LSTM as a hidden layer and a Dropout layer in order to prevent overfitting.

The third and most complex architecture consists of one Bidirectional LSTM layer, a Dropout layer in order to prevent overfitting, LSTM layer and two densely-connected NN layers.

The softmax function is used as the activation function in the output layer of all the neural network models 
since they predict a multinomial probability distribution. 
Adam optimizer was used since it achieves good results faster than classical stochastic gradient descent optimizer.

\subsection{Training the models}
Each model was trained for a period of 20, 50, 80 and 110 epochs in order to determine when underfitting and overfitting happens. 

\subsection{Generating the lyrics}
The lyrics are being generated line by line, with tokenized words from $n$
previous lines as the input for the model. Model then predicts for each unique
word from the corpus how likely it is to appear next. That word is added to
the song and then the model makes a new prediction for the next word with the
last one added to the input.

Since lyrics tend to be repetitive, especially after overfitting, the model may
fall in loop predicting the same lyrics over and over. That's why the
genrating function explicitly prevents two lines starting with the same word
by picking the second word that is the most likely to appear. It also reduces
the impact of overfitting by memorizing the exact lyrics from dataset:

Any song with identical words at the start of two close lines cannot be exactly
reproduced by the generator.

Number of lines is randomly selected from the same distribution as the numbers
of lines of lyrics in the dataset.

\subsection{Evaluation of the generated lyrics}
The measure of the model fitness during the training has been "how well the
model reproduces the lyrics it was given". However, the goal isn't to reproduce
the same lyrics that already exist, but to generate \textit{new} meaningful songs. 

Measuring how good some lyrics are is a problem of its own, because it's highly
subjective and hardly quantifiable. There are ways to analyze the structure of
generated lyrics and the distribution of the words \cite{b7}, but with such a
diverse dataset, there isn't a point of reference and that still isn't 
sufficient to tell if the lyrics really are good.



As part of our evaluation, we used The Lyric Assessor.
The Lyric Assessor is calibrated using the lyrics of 295 songs that are cited by songwriters as being examples of well-crafted songs. It scores the lyrics with a number ranging form -5 to 5. 
Scores above zero (maximum = 5) indicate that the lyrics are linguistically more like lyrics often mentioned as archetypically well-crafted songs by songwriters.
Scores below zero (minimum = -5) indicate that the lyrics are linguistically less like lyrics often mentioned as archetypically well-crafted songs by songwriters.
The Lyric Assessor has an accuracy of approximately 80\%. It uses computational linguistics to compare lyrics with a corpus of songs regarded as "well-crafted" by songwriters and with a corpus of songs not so regarded by songwriters.

\section{Project results}
The generated lyrics can be found in the Appendix \ref{APDX}.
Scores by the Lyric Assessor for the generated lyrics  are given in Table 
\ref{scores}. 

% converted the table according to the template:
\begin{table}[htbp] % "insert figures and tables after they're cited in the text"
\caption{The Lyric Assessor scores depending on model architecture and training time}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Number of}&\multicolumn{3}{|c|}{\textbf{Architecture}} \\
\cline{2-4} 
\textbf{epochs} & \textbf{\textit{SimpleRNN}}& \textbf{\textit{SimpleLSTM}}& \textbf{\textit{BiLSTM}} \\
\hline
20 & -0.9 & 1.9 & -4.3 \\ % inserting body of the table
50 & 1.7 & 2.1 & 1.6 \\
80 & -0.3 & 2.6 & 3.1 \\
110 & 1.3 & 0.5 & 0.8 \\
\hline
\end{tabular}
\label{scores}
\end{center}
\end{table}

\subsection{Comparison by architecture}
Comparison of the lyrics generated after 80 epochs by three different models:
\ref{LSTM80}, \ref{RNN80}, \ref{HID80}.
When comparing the results, we look at how well the song is crafted in terms of syntax and semantics, and the similarity to what is generally perceived as 'well written' lyrics. 
Simple RNN architecture generated lyrics where the verses lack syntactic sense and words following one another seem very random (\ref{RNN80}). 
The most complex architecture based on Bidirectional LSTM generated lyrics which demonstrated overfitting. After training the model for 80 epochs, it generated song lyrics asssembled from verses identical to existing songs from the dataset.
Architecture with one hidden LSTM layer and regularisation provided satisfactory results(\ref{LSTM80}). The generated lyrics improved in terms of syntax and semantics when compared to the ones generated by Simple RNN model. The words do not seem as random, while overfitting is avoided due to a balance of simpler architecture and right amount of epochs used for training the model.

\subsection{Comparison by epoch}
It can be concluded from the scoring, 
that for Simple LSTM results keep getting better up until 80 epochs. Training this particular model for more than 80 epochs decreases the score.
The more complex model based on Bidirectional LSTM seems to achieve the best score - 3.1 for 80 epochs. This makes sense since the song lyrics 
generated for this model after 80 epochs are almost identical to verses provided in the dataset, so The Lyric Assessor is more likely to consider 
this song archetypically well-crafted.

Kako se mijenjala dobrota lyricsa prema loss funkciji
\subsection{Comparison by artist}
Za dva artista oko kojih se dogovorimo: dvaput natreniramo onu arhitekturu koja
daje najbolje rezultate na broj epoha koji daje najbolje rezultate.
%Dylanometer

\section{Comparison with existing solutions}
For comparison, we have used an already existing project with a character-based approach with mild modifications.

The important difference from our solution is that this network must learn words and the order of the letters to get a meaningful word.
Also, has to learn the order between the words.

The project uses the Sequential model which is one way of creating deep learning models. 
It is convenient to use when each layer has only one input tensor and one output
tensor. The Sequential model is defined by passing a list of layers to the Sequential
constructor.

Firstly, words are presented as vectors that need to be evaluated to match
something meaningful and that is done by calling embedding. Embedding turns positive integers
into dense vectors of fixed size. 

After that, Gated Recurrent Units (GRU) is used to remember
a certain number of previous words in a clever way (rnn\_units). GRU is used as a closing mechanism in RNN (something like LSTM, but with fewer parameters). 

Finally, a dense layer is a deeply connected layer
from its preceding layer which works for changing the dimension of the output by
performing matrix-vector multiplication and gives information about the most probable word that
is expected.

We used similar parameters and architectures as with our model for comparison. 
The most noticeable disadvantage is that some words do not make sense, that is, we can call them ''garbage''.

An important parameter when generating lyrics is \textbf{temperature}. Low temperature will produce predictable results, but with 
higher temperature lyrics will become more creative.

skripta koja na početku ima dict
key:

\section{Conclusion}
The resulting lyrics generator doesn't produce completely random lyrics nor does
it really create lyrics that make sense. Given the limited resources and time,
the results are expected because this approach usually doesn't le

given the limited resources and time, results as expected:
results as expected: 
 - neither completely random nor really making sense
even better 

GPT-based 
That could have been expected because
even state-of-the art RNN-based lyrics generators perform 

Given the limited resources and time, the results are expected.
What was done, what could have been tried, possible additional work it enables
etc. How satisfied are we with the results.
% apostrofi - mogli smo ih pretvoriti u prave riječi bez apostrofa
% smanjenje broja memoriziranih riječi u tokenizeru po učestalosti
% probati bez n-grama? Fiksan broj riječi umjesto linija?

%dodati da bi nam alternativa bila brojanje slogova ili riječi ili nekaj 
% u zaključak - kaj bi se još moglo
 


\subsection{Figures and Tables}
\paragraph{Positioning Figures and Tables} 
Ovo je ostavljeno samo kako bi se kasnije moglo lakše kopirati ako treba.
Place figures and tables at the top and 
bottom of columns. Avoid placing them in the middle of columns. Large 
figures and tables may span across both columns. Figure captions should be 
below the figures; table heads should appear above the tables. Insert 
figures and tables after they are cited in the text. Use the abbreviation 
``Fig.~\ref{fig}'', even at the beginning of a sentence.

\begin{table}[htbp]
\caption{Table Type Styles}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
\cline{2-4} 
\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
\hline
copy& More table copy$^{\mathrm{a}}$& &  \\
\hline
\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
\end{tabular}
\label{tab1}
\end{center}
\end{table}

\begin{figure}[htbp]
\centerline{\includegraphics{fig1.png}}
\caption{Example of a figure caption.}
\label{fig}
\end{figure}


\section{Appendix}\label{APDX}

Ovdje ubacivati tekstove, subsectioni s labelama za referiranje.
Svaki subsection jedna "pjesma"

\subsection{Simple LSTM - 20th epoch}\label{LSTM20}
\subsection{Simple LSTM - 50th epoch}\label{LSTM50}
\subsection{Simple LSTM - 80th epoch}\label{LSTM80}
\subsection{Simple LSTM - 110th epoch}\label{LSTM110}
\subsection{Simple RNN - 20th epoch}\label{RNN20}
\subsection{Simple RNN - 50th epoch}\label{RNN50}
\subsection{Simple RNN - 80th epoch}\label{RNN80}
\subsection{Simple RNN - 110th epoch}\label{RNN110}
\subsection{LSTM (Hidden Layer) - 20th epoch}\label{HID20}
\subsection{LSTM (Hidden Layer) - 50th epoch}\label{HID50}
\subsection{LSTM (Hidden Layer) - 80th epoch}\label{HID80}
\subsection{LSTM (Hidden Layer) - 110th epoch}\label{HID110}

\subsection{Artist 1}\label{A1}
\subsection{Artist 2}\label{A2}

\subsection{Sequential - (256, 1024) - 30th epoch, 200 lyrics}\label{Sequential256_1024_200}
\subsection{Sequential - (256, 1024) - 30th epoch, 1000 lyrics}\label{Sequential256_1024_1000}
\subsection{Sequential - (256, 1024) - 30th epoch, 2000 lyrics}\label{Sequential256_1024_2000}
\subsection{Sequential - (512, 1024) - 30th epoch, 200 lyrics}\label{Sequential512_1024_200}
\subsection{Sequential - (512, 1024) - 30th epoch, 1000 lyrics}\label{Sequential512_1024_1000}
\subsection{Sequential - (512, 1024) - 30th epoch, 2000 lyrics}\label{Sequential512_1024_2000}
\subsection{Sequential - (512, 2048) - 30th epoch, 200 lyrics}\label{Sequential512_2048_200}
\subsection{Sequential - (256, 1024) - 50th epoch, 100 lyrics}\label{Sequential256_1024_100}

\section*{References}

\begin{thebibliography}{00}
\bibitem{b1} P. Potash, A. Romanov, and A. Rumshisky, GhostWriter: Using an LSTM for Automatic Rap Lyric Generation. In: \emph{Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing}, 2015.
\bibitem{b2} H. Nguyen, and B. Sa, Rap Lyrics Generator, unpublished, 2009.
\bibitem{b3} H. Manurung, G. Ritchie, and H. Thompson, Towards a Computational Model of Poetry Generation. In: \emph{Proceedings of AISB Symposium on Creative and Cultural Aspects and Applications of AI and Cognitive Science}, pp. 79-86, April 2000.
\bibitem{b4} H. Hirjee, and D. Brown, Using automated rhyme detection to characterize rhyming style in rap music, 2010.
\bibitem{b5} H. Hirjee, and D. Brown, Rhyme analyzer: An analysis tool for rap lyrics. In: \emph{Proceedings of the 11th International Society for Music Information Retrieval Conference}, 2010.
\bibitem{b6} R. Mayer, R. Neumayer, and A. Rauber, Rhyme and Style Features for Musical Genre Classification by Song Lyrics. In: \emph{ISMIR 2008, \nth{9} International Retrieval, 14-18 September, 2008, Drexel University, Philadelphia, PA, USA}.
\bibitem{b7} H. Gill, D. Lee1 and N. Marwell, Deep Learning in Musical Lyric Generation: An LSTM-Based Approach. In: \emph{Yale Undergraduate Research Journal, Vol 1.1}, September 2020.

\end{thebibliography}

\end{document}
